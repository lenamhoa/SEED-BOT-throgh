// SeedBot (Hybrid): seed ### tr∆∞·ªõc, kh√¥ng kh·ªõp th√¨ fallback AI
export default {
  async fetch(request, env) {
    if (request.method === "GET") return new Response("SeedBot OK", { status: 200 });
    if (request.method !== "POST") return new Response("Method not allowed", { status: 405 });

    const TOKEN = env.BOT_TOKEN;
    const OPENAI_API_KEY = env.OPENAI_API_KEY; // <-- ƒë√£ th√™m ·ªü b∆∞·ªõc 1

    const update = await request.json().catch(() => ({}));
    const msg = update.message || update.edited_message || {};
    const chatId = msg.chat?.id;
    const text = (msg.text || "").trim();
    if (!chatId || !text) return new Response(JSON.stringify({ ok: true }), { status: 200 });

    // 1) Seed map
    const seedMap = {
      101: "/optimize ‚Äì T·ªëi ∆∞u Windows 10 (BIOS + h·ªá th·ªëng)",
      102: "/servicemgm ‚Äì Qu·∫£n l√Ω d·ªãch v·ª• Windows (an to√†n, nh·∫π RAM)",
      103: "/netnvme ‚Äì T·ªëi ∆∞u m·∫°ng + SSD NVMe + TCP stack",
      104: "/gametweak ‚Äì T·ªëi ∆∞u ch∆°i game b·∫±ng batch script",
      105: "/security ‚Äì Registry Hardening cho Windows 10 (SAFE/OPTIONAL)",
      106: "/sound ‚Äì Preset Realtek EQ cho loa Microlab M105/M108",
      107: "/boot ‚Äì Boot USB v√† c√†i Win10 tr√™n NVMe",
      108: "/gpt ‚Äì Convert NVMe sang GPT v√† c√†i Windows",
      109: "/win10 ‚Äì T·∫°o USB c√†i Windows 10 chu·∫©n GPT+UEFI+NTFS",
      110: `/win10ltsc ‚Äì Windows 10 IoT Enterprise LTSC 2021
üß© Version 21H2 ‚Äì Build 19044.1288
‚úÖ Nh·∫π, kh√¥ng bloat, RAM th·∫•p, kh√¥ng update n·ªÅn
üîó ISO: https://drive.massgrave.dev/en-us_windows_10_iot_enterprise_ltsc_2021_x64_dvd_257ad90f.iso`,
      111: "/win10driver ‚Äì Driver t·ª± ƒë·ªông & th·ªß c√¥ng cho Win10 LTSC",
      201: "/sp ‚Äì H∆∞·ªõng d·∫´n x·ª≠ l√Ω ƒë∆°n Shopee (m√£ v·∫≠n ƒë∆°n)",
      202: "/suco ‚Äì X·ª≠ l√Ω khi ng∆∞·ªùi nh·∫≠n kh√¥ng b·∫Øt m√°y (AhaMove)",
      301: "/familylogic ‚Äì Ph√¢n t√≠ch h√†nh vi gia ƒë√¨nh (preset logic)",
      302: "/camdo ‚Äì V·ªÅ c√°m d·ªó v√† t·ªânh th·ª©c n·ªôi t√¢m",
      303: "/10nam ‚Äì H·ªìi ph·ª•c sau 10 nƒÉm h√¥n nh√¢n (kh√¥ng v·ªôi v√†ng)",
      401: "/i3 ‚Äì Build i3-8100 + B365M Gaming HD (RAM dual + XMP)",
      402: "/i312100 ‚Äì Build i3-12100F full ph·ª• ki·ªán (~10.5 tri·ªáu)",
      403: "/i5 ‚Äì PC i5-4690 + Win10 LTSC (r·∫ª m√† m∆∞·ª£t)",
      405: "/xeon ‚Äì Checklist Xeon E3-1275 v3 (l·∫Øp r√°p & t·ªëi ∆∞u)"
    };

    // 2) L·ªánh ti·ªán √≠ch
    if (/^\/start\b/i.test(text) || /^\/help\b/i.test(text)) {
      return send(TOKEN, chatId,
        "üëã Xin ch√†o! ‚Ä¢ G√µ: seed 110 ‚Üí tr·∫£ prompt /win10ltsc\n" +
        "‚Ä¢ Chat t·ª± do ‚Üí m√¨nh tr·∫£ l·ªùi b·∫±ng AI\n" +
        "‚Ä¢ /list ‚Üí xem c√°c seed c√≥ s·∫µn"
      );
    }
    if (/^\/list\b/i.test(text)) {
      const keys = Object.keys(seedMap).sort((a,b)=>Number(a)-Number(b));
      const lines = keys.map(k => `‚Ä¢ ${k} ‚Äì ${seedMap[k].split(" ‚Äì ")[0]}`);
      return send(TOKEN, chatId, "üìö Danh s√°ch seed:\n" + lines.join("\n"));
    }

    // 3) N·∫øu l√† "seed ###" ‚Üí tr·∫£ seed
    const m = text.match(/^seed\s*(\d{3})$/i);
    if (m) {
      const num = Number(m[1]);
      const payload = seedMap[num] || `‚ùå Kh√¥ng t√¨m th·∫•y seed ${num}`;
      return send(TOKEN, chatId, `üì¶ Seed ${num}:\n${payload}`);
    }

    // 4) Fallback AI (n·∫øu kh√¥ng kh·ªõp seed)
    const systemPrompt = `
B·∫°n l√† tr·ª£ l√Ω ti·∫øng Vi·ªát, s√∫c t√≠ch, l·ªãch s·ª±, tr·∫£ l·ªùi r√µ r√†ng.
∆Øu ti√™n h∆∞·ªõng d·∫´n t·ª´ng b∆∞·ªõc khi ng∆∞·ªùi d√πng h·ªèi c√°ch l√†m.
N·∫øu c√¢u h·ªèi m∆° h·ªì, ƒë∆∞a v√≠ d·ª• ng·∫Øn g·ªçn. Kh√¥ng b·ªãa link.
`.trim();

    try {
      const ai = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${OPENAI_API_KEY}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          model: "gpt-4o-mini",
          temperature: 0.3,
          messages: [
            { role: "system", content: systemPrompt },
            { role: "user", content: text }
          ]
        })
      });
      const data = await ai.json();
      const answer = data?.choices?.[0]?.message?.content?.trim()
        || "Xin l·ªói, hi·ªán m√¨nh ch∆∞a tr·∫£ l·ªùi ƒë∆∞·ª£c.";
      return send(TOKEN, chatId, answer);
    } catch (e) {
      console.error(e);
      return send(TOKEN, chatId, "‚ö†Ô∏è L·ªói g·ªçi AI. Th·ª≠ l·∫°i sau nh√©.");
    }
  }
};

function send(token, chatId, text) {
  const url = `https://api.telegram.org/bot${token}/sendMessage`;
  return fetch(url, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ chat_id: chatId, text })
  }).then(() => new Response(JSON.stringify({ ok: true }), { status: 200 }));
}