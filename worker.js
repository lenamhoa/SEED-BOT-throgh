// Telegram + Gemini with OpenAI fallback (Cloudflare Workers)
// - seed ###, /start, /list, /debug
// - Tráº£ lá»i báº±ng Gemini; náº¿u Gemini lá»—i/háº¿t quota -> fallback OpenAI

const seedMap = {
  "101": "/optimize â€“ Tá»‘i Æ°u Windows 10 (BIOS + há»‡ thá»‘ng)",
  "110": `/win10ltsc â€“ Windows 10 IoT Enterprise LTSC 2021
ğŸ§© Version 21H2 â€“ Build 19044.1288
âœ… Nháº¹, khÃ´ng bloat, RAM tháº¥p, khÃ´ng update ná»n
ğŸ“ ISO: https://drive.massgrave.dev/en-us_windows_10_iot_enterprise_ltsc_2021_x64_dvd_257ad90f.iso`,
};

const DEFAULT_GEMINI_MODEL = "gemini-1.5-flash";
const DEFAULT_OPENAI_MODEL = "gpt-4o-mini";

function sysPrompt() {
  return `Báº¡n lÃ  trá»£ lÃ½ tiáº¿ng Viá»‡t, sÃºc tÃ­ch, lá»‹ch sá»±. Tráº£ lá»i rÃµ rÃ ng theo tá»«ng bÆ°á»›c khi cáº§n, khÃ´ng bá»‹a link.`;
}

async function sendTelegram(token, chatId, text) {
  const url = `https://api.telegram.org/bot${token}/sendMessage`;
  await fetch(url, {
    method: "POST",
    headers: {"Content-Type": "application/json"},
    body: JSON.stringify({ chat_id: chatId, text }),
  });
}

/* ---------- Gemini ---------- */
async function callGemini(env, userText) {
  if (!env.GEMINI_API_KEY) return { status: 0, text: "", raw: "no_gemini_key" };

  const model = env.GEMINI_MODEL || DEFAULT_GEMINI_MODEL;
  const url = `https://generativelanguage.googleapis.com/v1beta/models/${encodeURIComponent(model)}:generateContent?key=${encodeURIComponent(env.GEMINI_API_KEY)}`;

  const body = {
    contents: [{ role: "user", parts: [{ text: `${sysPrompt()}\n\nNgÆ°á»i dÃ¹ng: ${userText}` }] }],
    generationConfig: { temperature: 0.3 },
    // ná»›i safety (váº«n tuÃ¢n chÃ­nh sÃ¡ch)
    safetySettings: [
      { category: "HARM_CATEGORY_DANGEROUS_CONTENT", threshold: "BLOCK_NONE" },
      { category: "HARM_CATEGORY_HARASSMENT",         threshold: "BLOCK_NONE" },
      { category: "HARM_CATEGORY_HATE_SPEECH",         threshold: "BLOCK_NONE" },
      { category: "HARM_CATEGORY_SEXUAL_CONTENT",      threshold: "BLOCK_NONE" }
    ]
  };

  const res = await fetch(url, {
    method: "POST",
    headers: {"Content-Type": "application/json"},
    body: JSON.stringify(body),
  });

  const raw = await res.text();
  let data = {};
  try { data = JSON.parse(raw); } catch {}
  const text =
    data?.candidates?.[0]?.content?.parts?.map(p => p.text).join("")?.trim() ||
    (data?.error?.message ? `âš ï¸ Gemini lá»—i: ${data.error.message}` : "");

  return { status: res.status, text: text || "", raw };
}

/* ---------- OpenAI (fallback) ---------- */
async function callOpenAI(env, userText) {
  if (!env.OPENAI_API_KEY) return { status: 0, text: "", raw: "no_openai_key" };

  const headers = {
    "Authorization": `Bearer ${env.OPENAI_API_KEY}`,
    "Content-Type": "application/json",
  };
  if (env.OPENAI_PROJECT) headers["OpenAI-Project"] = env.OPENAI_PROJECT;
  if (env.OPENAI_ORG) headers["OpenAI-Organization"] = env.OPENAI_ORG;

  const res = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers,
    body: JSON.stringify({
      model: env.OPENAI_MODEL || DEFAULT_OPENAI_MODEL,
      temperature: 0.3,
      messages: [
        { role: "system", content: sysPrompt() },
        { role: "user", content: userText },
      ],
    }),
  });

  const raw = await res.text();
  let data = {};
  try { data = JSON.parse(raw); } catch {}
  const text = data?.choices?.[0]?.message?.content?.trim() || (data?.error?.message ? `âš ï¸ OpenAI lá»—i: ${data.error.message}` : "");
  return { status: res.status, text: text || "", raw };
}

/* ---------- Handle Telegram ---------- */
async function handleTelegramUpdate(request, env) {
  let update = {};
  try { update = await request.json(); } catch {}
  const msg = update.message || update.edited_message || update.channel_post || {};
  const chatId = msg.chat?.id;
  const text = (msg.text || "").trim();
  if (!chatId || !text) return new Response("ok", { status: 200 });

  // /start, /help
  if (/^\/(start|help)\b/i.test(text)) {
    await sendTelegram(env.BOT_TOKEN, chatId,
      "ğŸ‘‹ Xin chÃ o!\nâ€¢ GÃµ: seed 110 â†’ tráº£ preset\nâ€¢ GÃµ cÃ¢u báº¥t ká»³ â†’ AI (Gemini, háº¿t quota sáº½ tá»± chuyá»ƒn OpenAI)\nâ€¢ /list â†’ xem seed\nâ€¢ /debug â†’ kiá»ƒm tra káº¿t ná»‘i");
    return new Response("ok");
  }

  // /list
  if (/^\/list\b/i.test(text)) {
    const lines = Object.keys(seedMap).sort((a,b)=>+a-+b).map(k => `â€¢ ${k} â€“ ${seedMap[k].split(" â€“ ")[0]}`);
    await sendTelegram(env.BOT_TOKEN, chatId, "ğŸ“š Danh sÃ¡ch seed:\n" + lines.join("\n"));
    return new Response("ok");
  }

  // /debug â€” soi keys & gá»i ping 2 bÃªn
  if (/^\/debug\b/i.test(text)) {
    const hasBot = !!env.BOT_TOKEN;
    const hasGem = !!env.GEMINI_API_KEY;
    const hasOai = !!env.OPENAI_API_KEY;

    let out = `hasBot=${hasBot} | hasGeminiKey=${hasGem} | hasOpenAIKey=${hasOai}`;

    if (hasGem) {
      const r = await callGemini(env, "HÃ£y tráº£ lá»i Ä‘Ãºng 1 tá»«: pong");
      out += `\nGemini status=${r.status} | ${r.raw.slice(0,160)}`;
    }
    if (hasOai) {
      const r2 = await callOpenAI(env, "HÃ£y tráº£ lá»i Ä‘Ãºng 1 tá»«: pong");
      out += `\nOpenAI status=${r2.status} | ${r2.raw.slice(0,160)}`;
    }

    await sendTelegram(env.BOT_TOKEN, chatId, out);
    return new Response("ok");
  }

  // seed ###
  const m = text.match(/^seed\s*(\d{3})$/i);
  if (m) {
    const code = m[1];
    const payload = seedMap[code] || `âŒ ChÆ°a cÃ³ seed ${code}.`;
    await sendTelegram(env.BOT_TOKEN, chatId, `ğŸ“¦ Seed ${code}:\n${payload}`);
    return new Response("ok");
  }

  // === Tráº£ lá»i AI: Gemini trÆ°á»›c, fail -> OpenAI ===
  let reply = "";
  let first = await callGemini(env, text);

  // Gemini OK náº¿u status 2xx vÃ  cÃ³ ná»™i dung khÃ´ng pháº£i lá»—i
  const geminiOk = first.status >= 200 && first.status < 300 && first.text && !/^âš ï¸ Gemini lá»—i/.test(first.text);

  if (geminiOk) {
    reply = first.text;
  } else {
    // Thá»­ OpenAI fallback náº¿u cÃ³ key
    const second = await callOpenAI(env, text);
    const openaiOk = second.status >= 200 && second.status < 300 && second.text && !/^âš ï¸ OpenAI lá»—i/.test(second.text);

    if (openaiOk) {
      reply = second.text;
    } else {
      // ThÃ´ng bÃ¡o thÃ¢n thiá»‡n theo tÃ¬nh huá»‘ng
      if (first.status === 429) {
        reply = "âš ï¸ Gemini Ä‘Ã£ Ä‘áº¡t giá»›i háº¡n sá»­ dá»¥ng hÃ´m nay. Thá»­ láº¡i sau hoáº·c báº­t OpenAI fallback.";
      } else if (second.status === 429) {
        reply = "âš ï¸ OpenAI Ä‘ang vÆ°á»£t giá»›i háº¡n/quota. Thá»­ láº¡i sau nhÃ©.";
      } else {
        reply = first.text || second.text || "âš ï¸ Hiá»‡n chÆ°a tráº£ lá»i Ä‘Æ°á»£c. Thá»­ láº¡i sau hoáº·c gÃµ /debug Ä‘á»ƒ kiá»ƒm tra.";
      }
    }
  }

  await sendTelegram(env.BOT_TOKEN, chatId, reply || "Xin lá»—i, chÆ°a cÃ³ cÃ¢u tráº£ lá»i.");
  return new Response("ok");
}

export default {
  async fetch(request, env) {
    if (request.method === "POST") return handleTelegramUpdate(request, env);
    return new Response("âœ… Bot Gemini + OpenAI fallback OK", { status: 200 });
  },
};