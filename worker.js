// === SeedBot Hybrid (Cloudflare Workers + Telegram + OpenAI) ===
// - "seed ###"  -> tr·∫£ preset (rule-based)
// - Kh√¥ng kh·ªõp -> fallback AI (GPT)
// - /start, /list, /debug (ki·ªÉm tra secrets + g·ªçi GPT test)
// ---------------------------------------------------------------

/** ====== 1) SEED PRESET ====== **/
const seedMap = {
  "101": "/optimize ‚Äì T·ªëi ∆∞u Windows 10 (BIOS + h·ªá th·ªëng)",
  "110": `/win10ltsc ‚Äì Windows 10 IoT Enterprise LTSC 2021
üß© Version 21H2 ‚Äì Build 19044.1288
‚úÖ Nh·∫π, kh√¥ng bloat, RAM th·∫•p, kh√¥ng update n·ªÅn
üìé ISO: https://drive.massgrave.dev/en-us_windows_10_iot_enterprise_ltsc_2021_x64_dvd_257ad90f.iso`,
  // Th√™m seed kh√°c ·ªü ƒë√¢y...
};

/** ====== 2) SYSTEM PROMPT CHO GPT ====== **/
function systemPrompt() {
  return `
B·∫°n l√† tr·ª£ l√Ω ti·∫øng Vi·ªát, s√∫c t√≠ch, l·ªãch s·ª±, gi·∫£i th√≠ch r√µ r√†ng theo t·ª´ng b∆∞·ªõc khi ph√π h·ª£p.
N·∫øu c√¢u h·ªèi m∆° h·ªì, h·ªèi l·∫°i 1 c√¢u ƒë·ªÉ l√†m r√µ r·ªìi tr·∫£ l·ªùi ng·∫Øn g·ªçn.
Kh√¥ng b·ªãa link. D√πng bullet khi c·∫ßn. Ng·∫Øn g·ªçn v·ª´a ƒë·ªß.
`.trim();
}

/** ====== 3) TI·ªÜN √çCH G·ª¨I TELEGRAM ====== **/
async function sendTelegram(token, chatId, text) {
  const url = `https://api.telegram.org/bot${token}/sendMessage`;
  const body = { chat_id: chatId, text };
  await fetch(url, {
    method: "POST",
    headers: {"Content-Type": "application/json"},
    body: JSON.stringify(body),
  });
}

/** ====== 4) G·ªåI OPENAI (H·ªñ TR·ª¢ sk-... & sk-proj-... ) ====== **/
async function callOpenAI(env, userText) {
  const headers = {
    "Authorization": `Bearer ${env.OPENAI_API_KEY}`,
    "Content-Type": "application/json",
  };
  // N·∫øu b·∫°n d√πng project-level key (sk-proj-...), c√≥ th·ªÉ b·ªï sung 2 bi·∫øn sau trong Build:
  // OPENAI_PROJECT (ID) v√†/ho·∫∑c OPENAI_ORG (ID). Kh√¥ng b·∫Øt bu·ªôc.
  if (env.OPENAI_PROJECT) headers["OpenAI-Project"] = env.OPENAI_PROJECT;
  if (env.OPENAI_ORG) headers["OpenAI-Organization"] = env.OPENAI_ORG;

  const res = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers,
    body: JSON.stringify({
      model: "gpt-4o-mini",
      temperature: 0.3,
      messages: [
        { role: "system", content: systemPrompt() },
        { role: "user", content: userText }
      ]
    }),
  });

  const data = await res.json().catch(() => ({}));
  let answer =
    data?.choices?.[0]?.message?.content?.trim() ||
    (data?.error?.message ? `‚ö†Ô∏è AI l·ªói: ${data.error.message}` : "");

  // N·∫øu r·ªóng, tr·∫£ th√¥ng b√°o m·∫∑c ƒë·ªãnh
  if (!answer) answer = "Xin l·ªói, m√¨nh ch∆∞a tr·∫£ l·ªùi ƒë∆∞·ª£c. H√£y th·ª≠ di·ªÖn ƒë·∫°t kh√°c ho·∫∑c g√µ /debug.";
  return { status: res.status, text: answer, raw: data };
}

/** ====== 5) X·ª¨ L√ù TELEGRAM UPDATE ====== **/
async function handleTelegramUpdate(request, env) {
  let update = {};
  try { update = await request.json(); } catch { /* ignore */ }
  const msg = update.message || update.edited_message || update.channel_post || {};
  const chatId = msg.chat?.id;
  const text = (msg.text || "").trim();

  if (!chatId || !text) return new Response("ok", { status: 200 });

  // /start, /help
  if (/^\/start\b/i.test(text) || /^\/help\b/i.test(text)) {
    await sendTelegram(env.BOT_TOKEN, chatId,
      "üëã Xin ch√†o!\n‚Ä¢ G√µ: seed 110 ‚Üí tr·∫£ preset\n" +
      "‚Ä¢ G√µ c√¢u b·∫•t k·ª≥ ‚Üí m√¨nh tr·∫£ l·ªùi b·∫±ng AI\n" +
      "‚Ä¢ /list ‚Üí xem danh s√°ch seed\n" +
      "‚Ä¢ /debug ‚Üí ki·ªÉm tra k·∫øt n·ªëi GPT"
    );
    return new Response("ok");
  }

  // /list
  if (/^\/list\b/i.test(text)) {
    const keys = Object.keys(seedMap).sort((a,b)=>Number(a)-Number(b));
    const lines = keys.map(k => `‚Ä¢ ${k} ‚Äì ${seedMap[k].split(" ‚Äì ")[0]}`);
    await sendTelegram(env.BOT_TOKEN, chatId, "üìö Danh s√°ch seed:\n" + lines.join("\n"));
    return new Response("ok");
  }

  // /debug ‚Äî ki·ªÉm tra secrets + g·ªçi GPT ping
  if (/^\/debug\b/i.test(text)) {
    const hasBot = !!env.BOT_TOKEN;
    const hasKey = !!env.OPENAI_API_KEY;
    let line = `hasBot=${hasBot} | hasKey=${hasKey}`;
    if (hasKey) {
      try {
        const res = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Authorization": `Bearer ${env.OPENAI_API_KEY}`,
            "Content-Type": "application/json",
            ...(env.OPENAI_PROJECT ? {"OpenAI-Project": env.OPENAI_PROJECT} : {}),
            ...(env.OPENAI_ORG ? {"OpenAI-Organization": env.OPENAI_ORG} : {}),
          },
          body: JSON.stringify({
            model: "gpt-4o-mini",
            temperature: 0.1,
            messages: [
              { role: "system", content: "Tr·∫£ l·ªùi ƒë√∫ng 1 t·ª´: pong" },
              { role: "user", content: "ping" }
            ]
          }),
        });
        const body = await res.text();
        line += `\nopenai_status=${res.status}\n${body.slice(0,300)}`;
      } catch (e) {
        line += `\nopenai_error=${String(e)}`;
      }
    }
    await sendTelegram(env.BOT_TOKEN, chatId, line);
    return new Response("ok");
  }

  // seed ### (v√≠ d·ª•: seed 110)
  const m = text.match(/^seed\s*(\d{3})$/i);
  if (m) {
    const code = m[1];
    const payload = seedMap[code] || `‚ùå Ch∆∞a c√≥ seed ${code}.`;
    await sendTelegram(env.BOT_TOKEN, chatId, `üì¶ Seed ${code}:\n${payload}`);
    return new Response("ok");
  }

  // Fallback AI
  if (!env.OPENAI_API_KEY) {
    await sendTelegram(env.BOT_TOKEN, chatId, "‚ö†Ô∏è Ch∆∞a c·∫•u h√¨nh OPENAI_API_KEY trong Build ‚Üí Variables & Secrets.");
    return new Response("ok");
  }

  try {
    const ai = await callOpenAI(env, text);
    await sendTelegram(env.BOT_TOKEN, chatId, ai.text);
  } catch (e) {
    await sendTelegram(env.BOT_TOKEN, chatId, "‚ö†Ô∏è L·ªói khi g·ªçi AI. Th·ª≠ l·∫°i sau nh√©.");
  }

  return new Response("ok");
}

/** ====== 6) WORKER ENTRY ====== **/
export default {
  async fetch(request, env) {
    if (request.method === "POST") return handleTelegramUpdate(request, env);
    return new Response("‚úÖ SeedBot OK", { status: 200 });
  },
};